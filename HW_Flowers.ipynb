{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "14JhnozCN6-7EbILRzEm7dgLdQWT362tP",
      "authorship_tag": "ABX9TyPDJVGAtjrm30EZL4ZKUSFN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Thanhnhat1211/Bai-Tap-AI/blob/main/HW_Flowers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgeMtvg4TQBa",
        "outputId": "6bd136a5-3967-458a-e441-b90dcec8a53e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "(59, 30, 40, 3) (59,)\n"
          ]
        }
      ],
      "source": [
        "from numpy import asarray\n",
        "from os import listdir\n",
        "from numpy import asarray,save\n",
        "from keras.utils import img_to_array,load_img\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from keras.models import load_model\n",
        "\n",
        "folder = '/content/drive/MyDrive/Flowers/'\n",
        "photos, labels=list (),list()\n",
        "for file in listdir(folder):\n",
        "  output=0.0\n",
        "  if file.startswith ('rose'):\n",
        "    output=1.0\n",
        "  if file.startswith ('lotus'):\n",
        "    output=2.0\n",
        "  if file.startswith ('iris'):\n",
        "    output = 3.0\n",
        "  if file.startswith ('daisy'):\n",
        "    output = 4.0\n",
        "  if file.startswith ('apricot'):\n",
        "    output = 5.0\n",
        "  img =load_img(folder+ file,target_size=(30,40))\n",
        "  photo = img_to_array(img)\n",
        "  photos.append(photo)\n",
        "  labels.append(output)\n",
        "photos =asarray(photos)\n",
        "labels =asarray(labels)\n",
        "print(photos.shape,labels.shape)\n",
        "save('flowers_photos.npy',photos)\n",
        "save('flowers_labels.npy',labels)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x_train = np.load('/content/flowers_photos.npy')\n",
        "y_train = np.load('/content/flowers_labels.npy')\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "x=x_train\n",
        "y=y_train\n",
        "from keras.utils import to_categorical\n",
        "x_train = x_train.astype('float32')/255\n",
        "y_train = to_categorical(y_train,100)"
      ],
      "metadata": {
        "id": "NxpT1KToTb04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4510209b-506b-4d5a-9932-51c127b875ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(59, 30, 40, 3)\n",
            "(59,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.backend import flatten\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Dropout,Flatten,Conv2D,MaxPooling2D,Normalization,LeakyReLU\n",
        "from keras.optimizers import Adam\n",
        "#32 lần\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32,kernel_size = (3,3),activation = 'relu',input_shape=(30,40,3),padding='Same'))\n",
        "model.add(MaxPooling2D((2,2),padding='same'))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "#64 lần\n",
        "model.add(Conv2D(64,(3,3),activation ='relu',padding ='same'))\n",
        "model.add(MaxPooling2D((2,2),padding='same'))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "#128 lần\n",
        "model.add(Conv2D(128,(3,3),activation ='relu',padding ='same'))\n",
        "model.add(MaxPooling2D((2,2),padding='same'))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "#256 lần\n",
        "model.add(Conv2D(256,(3,3),activation ='relu',padding ='same'))\n",
        "model.add(MaxPooling2D((2,2),padding='same'))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256,activation='relu'))\n",
        "model.add(LeakyReLU(alpha=0.1))\n",
        "model.add(Dense(100,activation='softmax'))\n",
        "\n",
        "from keras.losses import categorical_crossentropy\n",
        "model.compile(loss='categorical_crossentropy',optimizer=Adam(),metrics=['accuracy'])\n",
        "model.summary()\n",
        "train = model.fit(x_train,y_train,epochs=100,batch_size=64,verbose=1)"
      ],
      "metadata": {
        "id": "sttLSJkATfZ9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a1bb762-7b3e-402a-f63d-9a711aa9e1ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 30, 40, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 15, 20, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 15, 20, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 15, 20, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 8, 10, 64)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 10, 64)         0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 8, 10, 128)        73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 4, 5, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 4, 5, 128)         0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 4, 5, 256)         295168    \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 2, 3, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 2, 3, 256)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1536)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               393472    \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 100)               25700     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 807,588\n",
            "Trainable params: 807,588\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 4.6002 - accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.8036 - accuracy: 0.1864\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.4967 - accuracy: 0.2542\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.6671 - accuracy: 0.3051\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.9535 - accuracy: 0.1695\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.0041 - accuracy: 0.2712\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.1267 - accuracy: 0.2203\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.2837 - accuracy: 0.3220\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.3052 - accuracy: 0.2881\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.1295 - accuracy: 0.3051\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.0309 - accuracy: 0.1525\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.6675 - accuracy: 0.2203\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.5623 - accuracy: 0.3729\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.6247 - accuracy: 0.2881\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.7090 - accuracy: 0.2542\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.7810 - accuracy: 0.2203\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.8004 - accuracy: 0.2034\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.8041 - accuracy: 0.2034\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.7301 - accuracy: 0.2373\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.6797 - accuracy: 0.3220\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.6686 - accuracy: 0.3390\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.6216 - accuracy: 0.3559\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.6201 - accuracy: 0.4576\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.5827 - accuracy: 0.4068\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.4843 - accuracy: 0.4576\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.4025 - accuracy: 0.4746\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.3270 - accuracy: 0.5424\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.2846 - accuracy: 0.5085\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.2360 - accuracy: 0.5763\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.2488 - accuracy: 0.4576\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.1869 - accuracy: 0.4576\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.1170 - accuracy: 0.5932\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.0749 - accuracy: 0.5932\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 1.0247 - accuracy: 0.6102\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.0340 - accuracy: 0.5763\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.0102 - accuracy: 0.6780\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.0054 - accuracy: 0.6102\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.9645 - accuracy: 0.6271\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.9341 - accuracy: 0.6441\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.8683 - accuracy: 0.6441\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.8172 - accuracy: 0.6780\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.7980 - accuracy: 0.6441\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7611 - accuracy: 0.7119\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.8112 - accuracy: 0.7288\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.7342 - accuracy: 0.6780\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6633 - accuracy: 0.6949\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6193 - accuracy: 0.7288\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6108 - accuracy: 0.7627\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6891 - accuracy: 0.8136\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5872 - accuracy: 0.8136\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5714 - accuracy: 0.8305\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4675 - accuracy: 0.8305\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5634 - accuracy: 0.7458\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4483 - accuracy: 0.8644\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4996 - accuracy: 0.8136\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4232 - accuracy: 0.8644\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.3599 - accuracy: 0.8983\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5398 - accuracy: 0.7797\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2913 - accuracy: 0.9322\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.3735 - accuracy: 0.8814\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.4450 - accuracy: 0.8814\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.3020 - accuracy: 0.9153\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.3618 - accuracy: 0.8475\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.2624 - accuracy: 0.9492\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.3043 - accuracy: 0.8983\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.2884 - accuracy: 0.8983\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.2196 - accuracy: 0.9492\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.1929 - accuracy: 0.9153\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.2296 - accuracy: 0.9322\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.2109 - accuracy: 0.9153\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.1461 - accuracy: 0.9661\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.1463 - accuracy: 0.9492\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1676 - accuracy: 0.9153\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.1479 - accuracy: 0.9322\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.1123 - accuracy: 0.9661\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.1753 - accuracy: 0.9492\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.1568 - accuracy: 0.9492\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1339 - accuracy: 0.9492\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1769 - accuracy: 0.9153\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1387 - accuracy: 0.9153\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1343 - accuracy: 0.9661\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0883 - accuracy: 0.9661\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2469 - accuracy: 0.9322\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1288 - accuracy: 0.9661\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0867 - accuracy: 0.9661\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0882 - accuracy: 0.9661\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1218 - accuracy: 0.9322\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1450 - accuracy: 0.9492\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1194 - accuracy: 0.9492\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0980 - accuracy: 0.9492\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1136 - accuracy: 0.9492\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0711 - accuracy: 0.9831\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0758 - accuracy: 0.9661\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1352 - accuracy: 0.9492\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0808 - accuracy: 0.9661\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1283 - accuracy: 0.9661\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0988 - accuracy: 0.9661\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0739 - accuracy: 0.9661\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1037 - accuracy: 0.9831\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0445 - accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('flowers.h5')"
      ],
      "metadata": {
        "id": "dZkXSQHgTiSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1=load_model('flowers.h5')"
      ],
      "metadata": {
        "id": "J_WhWSxTTm3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from keras.utils import load_img\n",
        "from keras.utils.image_utils import img_to_array\n",
        "import numpy as np\n",
        "vat = {1: 'hoa hong',2:'hoa sen', 3:'iris', 4:'tieu cuc',5:'hoa mai vang'}\n",
        "img = load_img(\"/content/drive/MyDrive/Flowers/Sen.jpg\",target_size=(30,40))\n",
        "plt.imshow(img)\n",
        "img = img_to_array(img)\n",
        "img=img.reshape(1,30,40,3)\n",
        "img = img.astype('float32')\n",
        "img =img/255\n",
        "result  = np.argmax(model.predict(img),axis=1)\n",
        "vat[result[0]]"
      ],
      "metadata": {
        "id": "lSiTpvo7TpWQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "outputId": "69d7cad5-0137-431e-9e97-e8358146c7ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hoa hong'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhwAAAGdCAYAAABZ+qqcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAApaUlEQVR4nO3de5DU5Z3v8U9P3+Y+wzDMDQYcQEHDJRtWcVYlGCguqWNpoLbUZOtgNqWlO+SsstkkpBKN7lZNylQlblIs/rG7kpyKGt0SPfEkJIoyHCOQBSUEL7MwjjLIXGBgeu7dPd2/80fW2Yxy6W/TDz0zvF9VXQU932ee7zO/vnymp/v3+DzP8wQAAOBQTrYbAAAAkx+BAwAAOEfgAAAAzhE4AACAcwQOAADgHIEDAAA4R+AAAADOETgAAIBzgWw38HHJZFInTpxQUVGRfD5fttsBAADn4Hme+vr6VFNTo5yc87+GMe4Cx4kTJ1RbW5vtNgAAQIra2to0Y8aM89aMu8BRVFQkSbrpzv+lQCic0phY3oDLliRJ7595x1Sfn+83z5HsGTaPsZgWLDaPiQ/YfrbD8X7zHGaBElN5d46tp/x41FSfjv7XD5nqZ02tNM9xImgeYvJhbMRUXz11unmOykS3eYyFb6H9l5upPbbdIBJv95rnsPJfe51twKKrTOVet9vjIElXVU8z1XvJuHmOPuPjmdVA1N5TImmrjw3HzHNYDUX6Uq4dicX0+tNPjj53n4+zwLFlyxZ9//vfV0dHhxYvXqwf//jHuu66C98pPvozSiAUTjlwJMO2B7505IRsPyp/yB44fEG3+S8Qsj8DJWPGdV+KDBuwzZGTY6zXJbg9Gf9cGLjAS5VnncN+EzTxGXvK8dsb8jt+m5nPeL+WpEDQFjh8rg+EpEAoZBuQm2sqT4ZTeyy+GOE8W09e0v5zjSbc3rdjadxec4yBw/Pcv9UgHrL/0pXKWyCc3Jt//vOfa9OmTXrooYf0xhtvaPHixVq9erW6urpcTAcAAMY5J4HjBz/4ge6++259+ctf1jXXXKPHH39c+fn5+rd/+zcX0wEAgHEu44EjFovpwIEDWrly5X9PkpOjlStXas+ePZ+oj0aj6u3tHXMBAACTS8YDx6lTp5RIJFRZOfZNbpWVlero6PhEfWNjo0pKSkYvfEIFAIDJJ+sn/tq8ebMikcjopa2tLdstAQCADMv4RwrKy8vl9/vV2dk55vrOzk5VVVV9oj4cDit8Cd4BDQAAsifjr3CEQiEtWbJEO3fuHL0umUxq586dqq+vz/R0AABgAnBy0oRNmzZpw4YN+vM//3Ndd911euyxxzQwMKAvf/nLLqYDAADjnJPAcfvtt+vkyZN68MEH1dHRoU9/+tPasWPHJ95Iej4FnScVDKZ2MpuhUCTdVlOW3/3JN7yeTzDPflKaUMLtCYIKS/PMY/p9CVN9Muz+JEcV3bazBeZNsfU0Ei401acjMH2Wqf50r/3sgrEB4xmFjBaVnv80xh9387Q/M8/RdqbZPMZiV/Nx85iDH9jeZxY67v5EcqXFtpP6fbq23FRfHnd7W5KkzvdaTfXhwinmOeIjbtcR9NtPrpiba3sazkvxhJgXoyCU+h8/4tHUTxLm7LSQGzdu1MaNG119ewAAMIFk/VMqAABg8iNwAAAA5wgcAADAOQIHAABwjsABAACcI3AAAADnCBwAAMA5AgcAAHCOwAEAAJwjcAAAAOcIHAAAwDkCBwAAcI7AAQAAnCNwAAAA5wgcAADAOQIHAABwjsABAACcI3AAAADnCBwAAMA5AgcAAHCOwAEAAJwjcAAAAOcIHAAAwLlAths4F583IJ8XS6nWi0YcdyN5A7Y5+nqGzXPkBovMYywKC0rTGJRrKi+umGafwyhypa2+5a2jpvqS96K2CdLQMPd/mOoXhmeY5xjy+c1jLKZOKTPVLyi3r+H9oXbzGIue/dvMYw74TprqQ8VD5jmsTre8bap/+6l+U/2fzZhjqk/H9IVzTfVDYfvTVzAYNI+x8Ofa73NJf9xU39t3xjyH1ZlIV8q1I7HU++cVDgAA4ByBAwAAOEfgAAAAzhE4AACAcwQOAADgHIEDAAA4R+AAAADOETgAAIBzBA4AAOAcgQMAADhH4AAAAM4ROAAAgHMEDgAA4ByBAwAAOEfgAAAAzhE4AACAcwQOAADgHIEDAAA4R+AAAADOETgAAIBzBA4AAOAcgQMAADhH4AAAAM4ROAAAgHOBbDdwLqen+RUIpdZe3JfnuBspkDfdVD/S3WueozA8zTzGIlBQYR4znJOwzREuNs9hNaU/aqpfGKw11c8N5prq0/FXFStM9dNiheY5BsNB8xgLv/H7J1tOm+eYUzPDPMaiLGa/vSZywqb6gqvt9zur3JDtMTD6fsRU/+a7h0z16Xg91maqv2LqleY5wrluf8cumGK7bUhSboGtvi96xjyHVdfJD1OuTcRTf47gFQ4AAOBcxgPHd7/7Xfl8vjGX+fPnZ3oaAAAwgTj5k8qnPvUpvfzyy/89SWDc/uUGAABcAk6SQCAQUFVVlYtvDQAAJiAn7+E4cuSIampqNHv2bH3pS1/SsWPHzlkbjUbV29s75gIAACaXjAeOpUuXatu2bdqxY4e2bt2q1tZW3XTTTerr6ztrfWNjo0pKSkYvtbW2TxQAAIDxL+OBY+3atfrLv/xLLVq0SKtXr9Yvf/lL9fT06Jlnnjlr/ebNmxWJREYvbW22j0YBAIDxz/m7OUtLS3XVVVfp6NGjZ/16OBxWOGz/7DIAAJg4nJ+Ho7+/Xy0tLaqurnY9FQAAGKcyHji+9rWvqampSe+//75ef/11feELX5Df79edd96Z6akAAMAEkfE/qRw/flx33nmnuru7NW3aNN14443au3evpk1ze9puAAAwfmU8cDz99NMZ+T7D+SEFQqGUaqMxt3tGSFJekS0wlefYz0NyU9315jEWZaEy85jmI++a6gdbbfucpGPz6Vmm+pFi234ZsRq/qT4dU/KnmupPFvjMcxReM9s8xsI3OGyqf3f/m+Y5phn3MLL6i8X15jGdU4dM9UeHOsxzWEULbBtyFEzPN9X39vSY6tNx2mfb3yXy+9fNcwSCSfMYi7Jy+z5M02fZHgvKptmOXTpqp6e+d1M8NqK3UqxlLxUAAOAcgQMAADhH4AAAAM4ROAAAgHMEDgAA4ByBAwAAOEfgAAAAzhE4AACAcwQOAADgHIEDAAA4R+AAAADOZXwvlUwp6o0qEPJSqj1z4oTjbiSvf9BUX+LZzo8vSTf92dXmMRZLKxeYx7zbNcVUH+k5aZ7D6pqKmab69h7bXhYjnvv9YAJ+2+1pak3qext8ZGRGzDzGIpSw/b4y50bbHjiSVHDctl+L1V9V2e9zV8ds+3Ec6HH/+NQSTJjqAyHbfjBejdvbkiQdnjFiqu/yvWOeI9LTaR5j0Rc5ZR5zst32WBDw2Z9brApKU99/KhlL/bbHKxwAAMA5AgcAAHCOwAEAAJwjcAAAAOcIHAAAwDkCBwAAcI7AAQAAnCNwAAAA5wgcAADAOQIHAABwjsABAACcI3AAAADnCBwAAMA5AgcAAHCOwAEAAJwjcAAAAOcIHAAAwDkCBwAAcI7AAQAAnCNwAAAA5wgcAADAOQIHAABwjsABAACcI3AAAADnAtlu4FwSXR/KF0itvb4PWhx3I8WGo6b6ULLfPEcgmjCPsSgNFJjHXB2eaqr3ikLmOayOFtputh/GB031V5a7X0Ms8J+m+g97IuY5jrxhu81alQYLTfXz8mz1khQZSprHWMR+P2Qesyhi6+m6+Z81z2F1cma1qd5X02eqj/QcM9Wn4yenfmuqb7lmoXmO1pageYzF8dZ3zGM6jp021Q+cHjbPYRUIn0m5NplI/f7AKxwAAMA5AgcAAHCOwAEAAJwjcAAAAOcIHAAAwDkCBwAAcI7AAQAAnCNwAAAA5wgcAADAOQIHAABwjsABAACcG7d7qXR2fyC/P7U8NJhM/bzv6QpPLTHVx+J+8xzdQfu+DhYdfR32Md22PRTyou7P8z+v4gZTfeUs28/Vq7XtvZKO1zp2m+qH5uea5whdMc08xqL/7U5T/Rv/91XzHGU3/E/zGIvyM555TGW77fe0LuWb57D6/THbfXte5XRTfd0s255K6QgffNtUn1c4Yp8jt9Q8xiIUtD1PSJLn2Z6Gg75i8xxWYV/q60j4EpK6U6rlFQ4AAOAcgQMAADhnDhy7d+/WLbfcopqaGvl8Pj3//PNjvu55nh588EFVV1crLy9PK1eu1JEjRzLVLwAAmIDMgWNgYECLFy/Wli1bzvr1Rx99VD/60Y/0+OOPa9++fSooKNDq1as1POz+b/sAAGB8Mr9pdO3atVq7du1Zv+Z5nh577DF9+9vf1q233ipJ+ulPf6rKyko9//zzuuOOOy6uWwAAMCFl9D0cra2t6ujo0MqVK0evKykp0dKlS7Vnz56zjolGo+rt7R1zAQAAk0tGA0dHxx8/mlVZWTnm+srKytGvfVxjY6NKSkpGL7W1tZlsCQAAjANZ/5TK5s2bFYlERi9tbW3ZbgkAAGRYRgNHVVWVJKmzc+wJgTo7O0e/9nHhcFjFxcVjLgAAYHLJaOCoq6tTVVWVdu7cOXpdb2+v9u3bp/r6+kxOBQAAJhDzp1T6+/t19OjR0f+3trbq4MGDKisr08yZM3X//ffrH//xH3XllVeqrq5O3/nOd1RTU6Pbbrstk30DAIAJxBw49u/fr5tvvnn0/5s2bZIkbdiwQdu2bdPXv/51DQwM6J577lFPT49uvPFG7dixQ7m59r0gAADA5GAOHMuXL5fnnXvDI5/Pp0ceeUSPPPLIRTUGAAAmj6x/SgUAAEx+BA4AAOAcgQMAADhH4AAAAM4ROAAAgHMEDgAA4ByBAwAAOEfgAAAAzhE4AACAcwQOAADgHIEDAAA4Z95L5VIZHBpRjj+1PDSzcLbjbiRVVZvK+0J55il2vv2meYzFLVfPMo/J77XV93l+8xxW0dB/mOqPHQ+Z6ksq3K+h8Oo5pvqyRVea5zjjHTCPsai4sd1U/140ap7D/4ffm8dY1K5bbx7z9mttpvr4QdvPKR1/cfV8U33pvEpT/TNHXjHVp2OX/4ypvjJq3xA0mhwxj7EY9iXNY4J5tqfhQIn7jVD9YcNjoOFHyiscAADAOQIHAABwjsABAACcI3AAAADnCBwAAMA5AgcAAHCOwAEAAJwjcAAAAOcIHAAAwDkCBwAAcI7AAQAAnBu3e6lU1s2RP5hae+Fw2HE30qDPls3ivT3mOY4HPzSPsfjpWy+bx3wmMMVUX57MN89h1f0HW31VQZWpfqrftm9OOqInbfu7JFvt+7v097n9fSLoLzfVV52y7zMxpc/tQ1ROxL6/S6IrYqr/TK19Hxyr94YGTfX7hk+Y6l9ucbunjSTlJGxrONnfb56jpKTEPMbi+uuvN495veklU/17J1vMc1gtWrwo5dpEji/lWl7hAAAAzhE4AACAcwQOAADgHIEDAAA4R+AAAADOETgAAIBzBA4AAOAcgQMAADhH4AAAAM4ROAAAgHMEDgAA4ByBAwAAOEfgAAAAzhE4AACAcwQOAADgHIEDAAA4R+AAAADOETgAAIBzBA4AAOAcgQMAADhH4AAAAM4ROAAAgHMEDgAA4ByBAwAAOBfIdgPncmYk9TQUCMed9iJJ8eiAqd43fMY8R3dRrnmMxfN9Q+YxtYvWmeqvLVpgnsPq0It7TPUz5kZsE8SusNWnIdBfZKofCX9gnsPfO2weYzHiFZjqfZER8xzTfSXmMRbH33rfPKZ0yLMNGDbe/tIQnZdvqv/f7/4/U31Ljvs1VOba7hPDuX7zHMN99sdlG/tz0dy5c031pz5sM89h1dr8bsq1XjL1+wOvcAAAAOfMgWP37t265ZZbVFNTI5/Pp+eff37M1++66y75fL4xlzVr1mSqXwAAMAGZA8fAwIAWL16sLVu2nLNmzZo1am9vH7089dRTF9UkAACY2Mzv4Vi7dq3Wrl173ppwOKyqqqq0mwIAAJOLk/dw7Nq1SxUVFZo3b57uu+8+dXd3u5gGAABMEBn/lMqaNWu0bt061dXVqaWlRd/61re0du1a7dmzR37/J99VHI1GFY1GR//f29ub6ZYAAECWZTxw3HHHHaP/XrhwoRYtWqQ5c+Zo165dWrFixSfqGxsb9fDDD2e6DQAAMI44/1js7NmzVV5erqNHj57165s3b1YkEhm9tLW5/4wxAAC4tJyf+Ov48ePq7u5WdXX1Wb8eDocVDoddtwEAALLIHDj6+/vHvFrR2tqqgwcPqqysTGVlZXr44Ye1fv16VVVVqaWlRV//+tc1d+5crV69OqONAwCAicMcOPbv36+bb7559P+bNm2SJG3YsEFbt27VoUOH9JOf/EQ9PT2qqanRqlWr9A//8A+8igEAwGXMHDiWL18uzzv3udN//etfX1RDAABg8mEvFQAA4ByBAwAAOEfgAAAAzhE4AACAcwQOAADgHIEDAAA4R+AAAADOETgAAIBzBA4AAOAcgQMAADhH4AAAAM4ROAAAgHPmzdsulbz8KfIHgynVDvr6HXcjFYX9pvopebZ6SerzTprHWLT57T+n/4gdM9V/vnixeQ6rwhm2m21X8vemen9/oak+HT5f0lSfjLeb58gNjpjHWPgDlab6MyH77W+gqMQ8xiLZNWQeMzUeMtV3RbvMc1gdzrX9nA59cNRUX2B8/EtHIDe1x/uPFBTnmefo6e4wj7HYt/9185hlS5eY6uuqqs1zWO18+Tcp13qGhzJe4QAAAM4ROAAAgHMEDgAA4ByBAwAAOEfgAAAAzhE4AACAcwQOAADgHIEDAAA4R+AAAADOETgAAIBzBA4AAODcuN1LJTcnpEBOaufWHxiKOe5GKi4Mm+oLi4vNcxwdOm0eY5Estq1Bkna981tT/efzrjDPYfXpmRWm+oPNh0z1hd0RU306plXMMNX3nLL/bpAbmGoeY1E8bY6p/kzgffMc7WX2+5HFXM/+/ZPtJ0z17bPse35YPdd10FRfXGDbtyTc5faxSZLabdsLqSTomefwh9zuCROPxc1j3nvPtl9Vcdh27NIRDhWkXOslPQ1pMKVaXuEAAADOETgAAIBzBA4AAOAcgQMAADhH4AAAAM4ROAAAgHMEDgAA4ByBAwAAOEfgAAAAzhE4AACAcwQOAADgHIEDAAA4R+AAAADOETgAAIBzBA4AAOAcgQMAADhH4AAAAM4ROAAAgHMEDgAA4ByBAwAAOEfgAAAAzhE4AACAcwQOAADgHIEDAAA4F8h2A+cy2BuRPxBMqXY4EnHcjTScU2iqDxblmefIieeax1hUBO09He9631T/q47fmeewKvNfa6r/4GTIVO8PxE316SjPSe22/RH/iWnmOUKOf50ouaLcVD9r8C/Mc/RWTDGPsQim8dDRm0iY6n/Xd8w+idEh7z1T/bSEz1Q/vaDIVJ+Ortx+U/3QsP3g+XyeeYzFjZ+92Tym49gHtvpTp81zWOWXpP54k0wk1XMitds4r3AAAADnTIGjsbFR1157rYqKilRRUaHbbrtNzc3NY2qGh4fV0NCgqVOnqrCwUOvXr1dnZ2dGmwYAABOLKXA0NTWpoaFBe/fu1UsvvaR4PK5Vq1ZpYGBgtOaBBx7QL37xCz377LNqamrSiRMntG7duow3DgAAJg7Tezh27Ngx5v/btm1TRUWFDhw4oGXLlikSiehf//Vf9eSTT+pzn/ucJOmJJ57Q1Vdfrb179+r666/PXOcAAGDCuKj3cET+682aZWVlkqQDBw4oHo9r5cqVozXz58/XzJkztWfPnrN+j2g0qt7e3jEXAAAwuaQdOJLJpO6//37dcMMNWrBggSSpo6NDoVBIpaWlY2orKyvV0dFx1u/T2NiokpKS0UttbW26LQEAgHEq7cDR0NCgw4cP6+mnn76oBjZv3qxIJDJ6aWtru6jvBwAAxp+0zsOxceNGvfjii9q9e7dmzJgxen1VVZVisZh6enrGvMrR2dmpqqqqs36vcDiscDicThsAAGCCML3C4XmeNm7cqO3bt+uVV15RXV3dmK8vWbJEwWBQO3fuHL2uublZx44dU319fWY6BgAAE47pFY6GhgY9+eSTeuGFF1RUVDT6voySkhLl5eWppKREX/nKV7Rp0yaVlZWpuLhYX/3qV1VfX88nVAAAuIyZAsfWrVslScuXLx9z/RNPPKG77rpLkvTDH/5QOTk5Wr9+vaLRqFavXq1//ud/zkizAABgYjIFDs+78Hnoc3NztWXLFm3ZsiXtpiQpVOCXP+hPqXZKovii5kpFPMf2dpfOnNR6/1O5xfb9MixCZwbNY/pGBi5c9Cf+T+c+8xxWJ3PaTfXDoVJT/eyhd0316TjTafv49/Qz9n12SpMx8xiLfu9DU31e3nTzHKFet/tGdPacMY8ZHBky1Q8Puv+of354xFQf6bXtQ+JVzzLVpyMnbHvMjPfb9l6RpJGE2/vEFbWzzWPyQ7Y9riJl7vcOCwRSf74bicfV/i57qQAAgHGCwAEAAJwjcAAAAOcIHAAAwDkCBwAAcI7AAQAAnCNwAAAA5wgcAADAOQIHAABwjsABAACcI3AAAADnCBwAAMA5AgcAAHCOwAEAAJwjcAAAAOcIHAAAwDkCBwAAcI7AAQAAnCNwAAAA5wgcAADAOQIHAABwjsABAACcI3AAAADnCBwAAMC5QLYbOJeBZFT+ZCKl2ryA+2X0pdbKqJ405phfXp3GqNQFT35gHpN/xXRT/X8WDJnnsNra+4KpvrZqlal+RvS4qT4dfbFiU/2akpvNcxTIeKM16kq8a6rPC5aZ58hvajWPseibZh/TkTxtqv/sDZ+xT2L0y7dsP6fesiJT/e8/PGqqT0dPkd9Uf0VpqXmOYH6heYxFe2eHeUzf6UFT/Ujc7f1akkIKplybGPGlXMsrHAAAwDkCBwAAcI7AAQAAnCNwAAAA5wgcAADAOQIHAABwjsABAACcI3AAAADnCBwAAMA5AgcAAHCOwAEAAJwbt3upJPu75QukeG79Itu+AOkIJuKm+rx22/nxJanzlG2PBqv83DzzmJBCpvorhvPNc1jl91xtqp9WbFtDn1LfGyBdr+UkTfXNw78yz3FVeIp5jEV5stRUf9XUE+Y5rlntdn+hU0Pd5jGD+bY9YfYe2W2ew6q35T9N9ceDfab6wjlVpvp05OR5pvr+Hvux8/tsexhZxYbsv8PHR2xj/KER8xxWw7HUf7aJkdT74RUOAADgHIEDAAA4R+AAAADOETgAAIBzBA4AAOAcgQMAADhH4AAAAM4ROAAAgHMEDgAA4ByBAwAAOEfgAAAAzhE4AACAcwQOAADgHIEDAAA4ZwocjY2Nuvbaa1VUVKSKigrddtttam5uHlOzfPly+Xy+MZd77703o00DAICJxRQ4mpqa1NDQoL179+qll15SPB7XqlWrNDAwMKbu7rvvVnt7++jl0UcfzWjTAABgYglYinfs2DHm/9u2bVNFRYUOHDigZcuWjV6fn5+vqqqqzHQIAAAmvIt6D0ckEpEklZWVjbn+Zz/7mcrLy7VgwQJt3rxZg4OD5/we0WhUvb29Yy4AAGByMb3C8aeSyaTuv/9+3XDDDVqwYMHo9V/84hc1a9Ys1dTU6NChQ/rGN76h5uZmPffcc2f9Po2NjXr44YfTbQMAAEwAaQeOhoYGHT58WK+99tqY6++5557Rfy9cuFDV1dVasWKFWlpaNGfOnE98n82bN2vTpk2j/+/t7VVtbW26bQEAgHEorcCxceNGvfjii9q9e7dmzJhx3tqlS5dKko4ePXrWwBEOhxUOh9NpAwAATBCmwOF5nr761a9q+/bt2rVrl+rq6i445uDBg5Kk6urqtBoEAAATnylwNDQ06Mknn9QLL7ygoqIidXR0SJJKSkqUl5enlpYWPfnkk/r85z+vqVOn6tChQ3rggQe0bNkyLVq0yMkCAADA+GcKHFu3bpX0x5N7/aknnnhCd911l0KhkF5++WU99thjGhgYUG1trdavX69vf/vbGWsYAABMPOY/qZxPbW2tmpqaLqqhjxQUF8kfTK09n9/9GdoTiZipPi8vzzzH1NIp5jEWgTQ+BX3m5ClTfdeZHvMcVsmhhK1+qu3Y+YLu31OUk2+bYyTXZ56jJ2gfY9E72Geqj3od5jl+ffqEeYxFR3eXeczpXtuYzjPt5jmsTvXa7qdlNeWm+qsDtvp0lJdVmOrfD9jWLEmJeK55jEVsaMg8Zih67tNGnI03bJ/DKhYfuHDRf0mOpP54zF4qAADAOQIHAABwjsABAACcI3AAAADnCBwAAMA5AgcAAHCOwAEAAJwjcAAAAOcIHAAAwDkCBwAAcI7AAQAAnDPtpXIp+fLz5EtxL5UL7fGSESMjpnK/7PtY5MhvHmMRGxw2j4l0nTHV95zqNs9hVRKw7VOTHLLtpTLic3scJCmakzTVD6WxBUR3Xtw+yKDfFzXVnwna90XpmxM0j7EYqigxj+n+MPV9JiRpKM/tHkmSVF5tm6Mo1/Zz7Tvjfv8Of+y0qb50Vql5Dtd7qSQT9n2YPM+2N1TCc/86QdzwkJmIp/7cyCscAADAOQIHAABwjsABAACcI3AAAADnCBwAAMA5AgcAAHCOwAEAAJwjcAAAAOcIHAAAwDkCBwAAcI7AAQAAnBu3e6nE5SnpS22PlNxQyHE3Ur7PtjfKyLBtnwlJikQi5jEWgydt+6JIUqzPtm9EYcjtXgWS5He810k87nYPEkkaHrbtaxP02fbykaREgds9huJB2/4agzn95jlKQuXmMRZVM2rMY6YWFZvqYwn7sbMqLbPtpdLb22OqP36izVSfjjOe7ed0hc/++3Ig7Pa5orTUvpdKXp5tTE6OfU8sq2isN+XakVhczTqQUi2vcAAAAOcIHAAAwDkCBwAAcI7AAQAAnCNwAAAA5wgcAADAOQIHAABwjsABAACcI3AAAADnCBwAAMA5AgcAAHCOwAEAAJwjcAAAAOcIHAAAwDkCBwAAcI7AAQAAnCNwAAAA5wgcAADAOQIHAABwjsABAACcI3AAAADnCBwAAMA5AgcAAHAukO0GPs7zPElSIj6S8piE53PVzn/PYegnnXpJUjpjDJIjCfuYZNI2wDNPYZb02XoyH7tLsIhEzG+qH/HbbxvxqNvfJ0ZicVN9PBozzxFPRs1jLPw++0NgPGrrKZ5we7+WpNjwsKneuoaE8Vinw/Nsj0/p3J6SPre3p3jU/lwUj9nWkZNjX7eV5b79Ue1Hz93n4/NSqbqEjh8/rtra2my3AQAAUtTW1qYZM2act2bcBY5kMqkTJ06oqKhIPt/YtNjb26va2lq1tbWpuLg4Sx1eWpfjmqXLc92X45ol1n05rftyXLM0udfteZ76+vpUU1OjnJzzv6o67v6kkpOTc8GUVFxcPOkO2oVcjmuWLs91X45rllj35eRyXLM0edddUlKSUh1vGgUAAM4ROAAAgHMTKnCEw2E99NBDCofD2W7lkrkc1yxdnuu+HNcsse7Lad2X45qly3fdHzfu3jQKAAAmnwn1CgcAAJiYCBwAAMA5AgcAAHCOwAEAAJybMIFjy5YtuuKKK5Sbm6ulS5fqd7/7XbZbcuq73/2ufD7fmMv8+fOz3VZG7d69W7fccotqamrk8/n0/PPPj/m653l68MEHVV1drby8PK1cuVJHjhzJTrMZdKF133XXXZ849mvWrMlOsxnS2Nioa6+9VkVFRaqoqNBtt92m5ubmMTXDw8NqaGjQ1KlTVVhYqPXr16uzszNLHWdGKutevnz5J473vffem6WOL97WrVu1aNGi0ZNc1dfX61e/+tXo1yfjcZYuvO7JdpzTMSECx89//nNt2rRJDz30kN544w0tXrxYq1evVldXV7Zbc+pTn/qU2tvbRy+vvfZatlvKqIGBAS1evFhbtmw569cfffRR/ehHP9Ljjz+uffv2qaCgQKtXr9awcaOq8eZC65akNWvWjDn2Tz311CXsMPOamprU0NCgvXv36qWXXlI8HteqVas0MDAwWvPAAw/oF7/4hZ599lk1NTXpxIkTWrduXRa7vniprFuS7r777jHH+9FHH81SxxdvxowZ+t73vqcDBw5o//79+tznPqdbb71Vb731lqTJeZylC69bmlzHOS3eBHDdddd5DQ0No/9PJBJeTU2N19jYmMWu3HrooYe8xYsXZ7uNS0aSt3379tH/J5NJr6qqyvv+978/el1PT48XDoe9p556KgsduvHxdXue523YsMG79dZbs9LPpdLV1eVJ8pqamjzP++OxDQaD3rPPPjta884773iSvD179mSrzYz7+Lo9z/M++9nPen/7t3+bvaYugSlTpnj/8i//ctkc5498tG7PuzyO84WM+1c4YrGYDhw4oJUrV45el5OTo5UrV2rPnj1Z7My9I0eOqKamRrNnz9aXvvQlHTt2LNstXTKtra3q6OgYc9xLSkq0dOnSSX/cJWnXrl2qqKjQvHnzdN9996m7uzvbLWVUJBKRJJWVlUmSDhw4oHg8PuZ4z58/XzNnzpxUx/vj6/7Iz372M5WXl2vBggXavHmzBgcHs9FexiUSCT399NMaGBhQfX39ZXOcP77uj0zW45yqcbd528edOnVKiURClZWVY66vrKzUu+++m6Wu3Fu6dKm2bdumefPmqb29XQ8//LBuuukmHT58WEVFRdluz7mOjg5JOutx/+hrk9WaNWu0bt061dXVqaWlRd/61re0du1a7dmzR36/P9vtXbRkMqn7779fN9xwgxYsWCDpj8c7FAqptLR0TO1kOt5nW7ckffGLX9SsWbNUU1OjQ4cO6Rvf+Iaam5v13HPPZbHbi/OHP/xB9fX1Gh4eVmFhobZv365rrrlGBw8enNTH+VzrlibncbYa94HjcrV27drRfy9atEhLly7VrFmz9Mwzz+grX/lKFjuDa3fcccfovxcuXKhFixZpzpw52rVrl1asWJHFzjKjoaFBhw8fnnTvSbqQc637nnvuGf33woULVV1drRUrVqilpUVz5sy51G1mxLx583Tw4EFFIhH9+7//uzZs2KCmpqZst+XcudZ9zTXXTMrjbDXu/6RSXl4uv9//iXcxd3Z2qqqqKktdXXqlpaW66qqrdPTo0Wy3ckl8dGwv9+MuSbNnz1Z5efmkOPYbN27Uiy++qFdffVUzZswYvb6qqkqxWEw9PT1j6ifL8T7Xus9m6dKlkjShj3coFNLcuXO1ZMkSNTY2avHixfqnf/qnSX+cz7Xus5kMx9lq3AeOUCikJUuWaOfOnaPXJZNJ7dy5c8zfxia7/v5+tbS0qLq6OtutXBJ1dXWqqqoac9x7e3u1b9++y+q4S9Lx48fV3d09oY+953nauHGjtm/frldeeUV1dXVjvr5kyRIFg8Exx7u5uVnHjh2b0Mf7Qus+m4MHD0rShD7eH5dMJhWNRiftcT6Xj9Z9NpPxOF9Qtt+1moqnn37aC4fD3rZt27y3337bu+eee7zS0lKvo6Mj260583d/93ferl27vNbWVu+3v/2tt3LlSq+8vNzr6urKdmsZ09fX57355pvem2++6UnyfvCDH3hvvvmm98EHH3ie53nf+973vNLSUu+FF17wDh065N16661eXV2dNzQ0lOXOL8751t3X1+d97Wtf8/bs2eO1trZ6L7/8sveZz3zGu/LKK73h4eFst562++67zyspKfF27drltbe3j14GBwdHa+69915v5syZ3iuvvOLt37/fq6+v9+rr67PY9cW70LqPHj3qPfLII97+/fu91tZW74UXXvBmz57tLVu2LMudp++b3/ym19TU5LW2tnqHDh3yvvnNb3o+n8/7zW9+43ne5DzOnnf+dU/G45yOCRE4PM/zfvzjH3szZ870QqGQd91113l79+7NdktO3X777V51dbUXCoW86dOne7fffrt39OjRbLeVUa+++qon6ROXDRs2eJ73x4/Gfuc73/EqKyu9cDjsrVixwmtubs5u0xlwvnUPDg56q1at8qZNm+YFg0Fv1qxZ3t133z3hw/XZ1ivJe+KJJ0ZrhoaGvL/5m7/xpkyZ4uXn53tf+MIXvPb29uw1nQEXWvexY8e8ZcuWeWVlZV44HPbmzp3r/f3f/70XiUSy2/hF+Ou//mtv1qxZXigU8qZNm+atWLFiNGx43uQ8zp53/nVPxuOcDranBwAAzo3793AAAICJj8ABAACcI3AAAADnCBwAAMA5AgcAAHCOwAEAAJwjcAAAAOcIHAAAwDkCBwAAcI7AAQAAnCNwAAAA5wgcAADAuf8PPg71a6Bm40MAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}